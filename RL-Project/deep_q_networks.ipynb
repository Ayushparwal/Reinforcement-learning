{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349de18-9384-405d-86f6-dcc631b616ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/10 completed. Epsilon: 0.01\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # remove HTML tags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove special characters\n",
    "    text = re.sub(r'\\d+', '', text)  # remove numbers\n",
    "    text = text.lower().strip()  # lowercase and strip whitespace\n",
    "    return text\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.dropna(inplace=True)  # Remove missing values\n",
    "df.drop_duplicates(inplace=True)  # Remove duplicates\n",
    "df = df[df['Sentiment'].isin(['positive', 'neutral', 'negative'])]  # Keep only known sentiments\n",
    "df['Sentence'] = df['Sentence'].apply(clean_text)  # Clean sentences\n",
    "\n",
    "# Preprocess text and labels\n",
    "sentences = df['Sentence'].values\n",
    "labels = df['Sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2}).values\n",
    "\n",
    "# TF-IDF encoding\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(sentences).toarray()\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# DQN Parameters\n",
    "state_size = X.shape[1]\n",
    "num_actions = 3\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "gamma = 0.95\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "memory = deque(maxlen=2000)\n",
    "\n",
    "# DQN Model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.out(x)\n",
    "\n",
    "model = DQN(state_size, num_actions)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Epsilon-greedy policy\n",
    "def act(state):\n",
    "    global epsilon\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return random.randrange(num_actions)\n",
    "    state = torch.FloatTensor(state).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        q_values = model(state)\n",
    "    return torch.argmax(q_values).item()\n",
    "\n",
    "# Replay function\n",
    "def replay():\n",
    "    global epsilon\n",
    "    if len(memory) < batch_size:\n",
    "        return\n",
    "    minibatch = random.sample(memory, batch_size)\n",
    "    for state, action, reward, next_state, done in minibatch:\n",
    "        state = torch.FloatTensor(state)\n",
    "        next_state = torch.FloatTensor(next_state)\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target += gamma * torch.max(model(next_state)).item()\n",
    "        target_f = model(state)\n",
    "        target_val = target_f.clone()\n",
    "        target_val[action] = target\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(target_f, target_val.detach())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "# Training loop\n",
    "episodes = 10\n",
    "for e in range(episodes):\n",
    "    for i in range(len(X_train)):\n",
    "        state = X_train[i]\n",
    "        action = act(state)\n",
    "        reward = 1 if action == y_train[i] else -1\n",
    "        done = True  # One-step\n",
    "        next_state = X_train[i]\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "        replay()\n",
    "    print(f\"Episode {e+1}/{episodes} completed. Epsilon: {epsilon:.2f}\")\n",
    "\n",
    "# Evaluation\n",
    "correct = 0\n",
    "total = len(X_test)\n",
    "for i in range(total):\n",
    "    state = torch.FloatTensor(X_test[i]).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(model(state)).item()\n",
    "    if pred == y_test[i]:\n",
    "        correct += 1\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f73c0-1a50-4894-9035-5ce584d814bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
